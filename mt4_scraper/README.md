# MT4 Scraper - Modular Version

A modular, industry-standard implementation of the MT4 trading report scraper that follows clean architecture principles.

## ğŸ—ï¸ Project Structure

```
mt4_scraper/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py          # Configuration constants
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logging_utils.py     # Logging setup
â”‚   â”œâ”€â”€ parsing_utils.py     # Data parsing utilities
â”‚   â””â”€â”€ file_utils.py        # File operations
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ data_models.py       # Data structures
â”œâ”€â”€ parsers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_parser.py       # Base parsing functionality
â”‚   â”œâ”€â”€ header_parser.py     # Header information parser
â”‚   â”œâ”€â”€ trade_parsers.py     # Trade data parsers
â”‚   â”œâ”€â”€ summary_parser.py    # Summary and performance parser
â”‚   â””â”€â”€ main_parser.py       # Main parser coordinator
â””â”€â”€ main.py                  # Main orchestrator
```

## ğŸš€ Features

- **Modular Architecture**: Clean separation of concerns
- **Industry Standards**: Follows Python best practices
- **Type Hints**: Full type annotation support
- **Data Parsing**: Complete MT4 HTML report parsing
- **Structured Data**: Returns well-organized data objects
- **Logging**: Detailed file-specific logging with progress tracking

## ğŸ“¦ Installation

1. Ensure you have Python 3.7+ installed
2. Install required dependencies:
   ```bash
   pip install beautifulsoup4 pandas
   ```

## ğŸ› ï¸ Usage

### Basic Usage

```python
from mt4_scraper.main import MT4Scraper

# Initialize scraper
scraper = MT4Scraper(input_file="10.htm")

# Run analysis and get data
try:
    analysis = scraper.run_analysis()

    # Access the parsed data
    print(f"Account: {analysis.header_information.account_number}")
    print(f"Closed Trades: {len(analysis.closed_transactions.trades)}")
    print(f"Open Trades: {len(analysis.open_trades.trades)}")
    print(f"Balance: {analysis.summary_section.balance}")

except Exception as e:
    print(f"Error: {e}")
```

### Command Line Usage

```bash
python mt4_scraper/main.py
```

### Custom File Processing

```python
# Process any MT4 HTML file
scraper = MT4Scraper(input_file="your_report.htm")
analysis = scraper.run_analysis()

# Work with the returned data
header = analysis.header_information
trades = analysis.closed_transactions.trades
summary = analysis.summary_section
```

## ğŸ”§ Configuration

All configuration is centralized in `config/settings.py`:

- Default input file
- Logging settings
- HTML parsing options
- Field mappings for data extraction
- Section headers and labels

## ğŸ“Š Data Models

The scraper extracts the following data structures:

- **HeaderInformation**: Account details, currency, leverage, etc.
- **ClosedTransactions**: Closed trade data with P/L
- **OpenTrades**: Open positions with floating P/L
- **WorkingOrders**: Pending orders
- **SummarySection**: Account summary data
- **PerformanceDetails**: Trading performance metrics

## ğŸ§ª Validation

The modular version includes comprehensive validation:

- **Output Validation**: Ensures all required sections are present
- **Data Integrity**: Cross-validates between JSON and CSV outputs
- **Comparison Tooling**: Compare with original scraper output

## ğŸ“ˆ Benefits of Modularization

1. **Maintainability**: Easier to modify individual components
2. **Testability**: Each module can be tested independently
3. **Reusability**: Components can be reused in other projects
4. **Readability**: Clear separation of concerns
5. **Scalability**: Easy to add new features or parsers

## ğŸ” Comparison Results

When compared to the original monolithic version:

- **Functionality**: 100% preserved
- **Performance**: Comparable execution times
- **Code Size**: Reduced through modularization
- **Maintainability**: Significantly improved
- **Testability**: Greatly enhanced

## ğŸ¤ Contributing

1. Follow the existing modular structure
2. Add type hints for new functions
3. Include docstrings for documentation
4. Add validation for new features
5. Update tests accordingly

## ğŸ“„ License

This project maintains the same license as the original scraper.
